# 语音对话端到端实现计划

> 目标：ESP32 采集声音 → Spring Boot + PaddleSpeech ASR → DeepSeek-R1-Distill → PaddleSpeech TTS → 音频下发给 ESP32 → MAX98357A 喇叭播放

---

## 一、总体流程图

```
┌─────────────┐    ① 上传音频      ┌──────────────────┐    ② ASR       ┌─────────────────┐
│   ESP32     │ ─────────────────→ │  Spring Boot     │ ─────────────→ │  PaddleSpeech   │
│ 麦克风采集   │   (HTTP POST       │  后端服务         │   (调用 ASR)   │  ASR (语音→文字) │
│ 录音并上传   │    multipart)     │                  │ ←───────────── │                 │
└─────────────┘                    │                  │    文字        └─────────────────┘
       ↑                           │                  │
       │                           │     ③ 请求大模型  │
       │                           │ ───────────────→ │  DeepSeek-R1   │
       │                           │ ←─────────────── │  (vLLM HTTP)   │
       │                           │    回复文字       │                 │
       │                           │                  │    ④ TTS       ┌─────────────────┐
       │                           │ ───────────────→ │  PaddleSpeech  │
       │                           │ ←─────────────── │  TTS (文字→语音)│
       │                           │    音频 URL/文件  │                 └─────────────────┘
       │                           └──────────────────┘
       │     ⑤ 下载音频                 │
       │ ←─────────────────────────────┘  (返回 TTS 音频 URL 或通过 WebSocket 推送)
       │
       ▼
┌─────────────┐    ⑥ I2S 输出
│   ESP32     │ ───────────────→  MAX98357A  →  喇叭播放
│ HTTP GET    │    解码 MP3/PCM
│ 解码并播放   │
└─────────────┘
```

---

## 二、计划步骤总览

| 步骤 | 环节 | 输入 | 输出 | 负责模块 |
|------|------|------|------|----------|
| **1** | ESP32 声音采集并上传 | 环境声音（麦克风） | 音频文件（WAV，16kHz 单声道）上传到后端 | ESP32 + 麦克风 |
| **2** | 后端接收并做 ASR | 上传的音频文件 | 文字 | Spring Boot + PaddleSpeech ASR |
| **3** | 将文字发送给大模型 | 用户文字 | 大模型回复文字 | Spring Boot → DeepSeek-R1-Distill（vLLM） |
| **4** | 将回复文字转为语音 | 回复文字 | 音频文件（WAV/MP3） | Spring Boot + PaddleSpeech TTS |
| **5** | 将音频下发给 ESP32 | 音频 URL 或推送 | 音频数据到达 ESP32 | Spring Boot 提供 URL；ESP32 拉取 |
| **6** | ESP32 播放声音 | 音频数据（MP3/WAV） | 喇叭出声 | ESP32 + MAX98357A + 喇叭 |

下面按步骤逐项说明实现要点和与现有文档的对应关系。

---

## 三、各步骤详细说明

---

### 步骤 1：ESP32 通过麦克风采集声音并上传

#### 1.1 目标

- 在 ESP32 上接**麦克风**，按「按键/触摸」或「持续检测到人声」触发录音。
- 录成符合 PaddleSpeech ASR 要求的格式：**16kHz、16bit、单声道 WAV**。
- 通过 **HTTP POST（multipart/form-data）** 把整段音频上传到 Spring Boot 提供的接口（如 `/api/voice/upload`）。

#### 1.2 硬件

- **麦克风**：  
  - 推荐 **I2S 数字麦克风**（如 **INMP441**），与 ESP32 用 I2S 连接，音质好、便于直接得到 16bit 采样。  
  - 若套件里是「声音传感器」（仅做音量检测），无法直接用于 ASR，需另配 I2S 麦克风或模拟麦克风+ADC。
- **接线**：INMP441 的 SCK/WS/SD 分别接 ESP32 的 I2S 时钟、左右时钟、数据输入（可与 MAX98357A 共用 BCLK/LRC，数据用另一 GPIO 作 DIN 输入）。
- **MAX98357A + 喇叭**：按 `doc/ESP32-I2S网络音频播放.md` 接好，本步骤只做录音和上传，播放在步骤 6。

#### 1.3 软件要点

- **录音**：用 ESP-IDF 的 I2S 驱动（输入）以 16kHz、16bit、Mono 采样，写入内存缓冲区（或先写 SPIFFS/SD 卡再读）。
- **WAV 封装**：在数据前加 44 字节 WAV 头（采样率 16000、1 声道、16bit），生成完整 WAV 再上传。
- **上传**：使用 `esp_http_client` 或 `HttpClient` 库，POST 到 `http://后端IP:端口/api/voice/upload`，body 为 `multipart/form-data`，字段名如 `file`，值为 WAV 二进制。
- **触发方式**：可用 GPIO 按键、触摸、或简单 VAD（检测到持续一段时间超过阈值再开始录），录满 N 秒或再次按键结束。

#### 1.4 与文档对应

- 麦克风接线与 I2S 输入配置：可参考 `doc/ESP32-I2S网络音频播放.md` 中的 I2S 引脚与时钟配置思路，改为输入。
- 若暂无 I2S 麦克风，可先在后端用「上传测试用 WAV 文件」的方式验证步骤 2～6，再补 ESP32 录音。

---

### 步骤 2：Spring Boot 接收音频并用 PaddleSpeech ASR 转成文字

#### 2.1 目标

- 后端提供接口（如 `POST /api/voice/upload`），接收 ESP32 上传的音频文件。
- 将收到的文件保存为临时 WAV（或先转码为 16kHz 单声道 16bit，再保存）。
- 调用 PaddleSpeech ASR，得到**用户说的文字**，作为后续发给大模型的输入。

#### 2.2 接口约定（示例）

- **请求**：`POST /api/voice/upload`，`Content-Type: multipart/form-data`，字段名 `file`，值为 WAV 文件。
- **响应**：JSON，如 `{ "text": "用户说出的文字" }`。若 ASR 失败可返回 `{ "error": "原因" }`。

#### 2.3 调用 PaddleSpeech ASR 的两种方式

**方式 A：Java 调 Python 命令行（适合先跑通）**

- 安装与使用见 `doc/PaddleSpeech-本地部署.md`。
- 在服务器上执行：  
  `paddlespeech asr --lang zh --input 临时文件.wav`  
  输出即为识别文字。
- Spring Boot 中：保存上传文件为临时路径，用 `ProcessBuilder` 执行上述命令，读取标准输出并解析出文字，再删除临时文件。

**方式 B：PaddleSpeech 以 HTTP 服务形式提供 ASR**

- 使用 PaddleSpeech 的 Server 模式（见 `doc/PaddleSpeech-本地部署.md` 第七章），启动 ASR 服务（如 `127.0.0.1:8090`）。
- Spring Boot 用 `RestTemplate` 或 `WebClient` 向该服务发送音频（或音频 URL），请求返回 JSON 中的识别结果。

#### 2.4 音频格式

- PaddleSpeech ASR 要求：**16kHz、16bit、单声道 WAV**。
- 若 ESP32 上传的已是该格式，可直接用；否则后端用 **ffmpeg** 或 **javax.sound.sampled** 转码后再调用 ASR。

#### 2.5 与文档对应

- 安装、命令行与 Python 调用：`doc/PaddleSpeech-本地部署.md` 第四、五节。
- 跨局域网访问 ASR 服务时：`doc/PaddleSpeech-本地部署.md` 第七章（续）内网穿透/公网部署。

---

### 步骤 3：将文字发送给 DeepSeek-R1-Distill 大模型

#### 3.1 目标

- 把步骤 2 得到的**用户文字**作为一条 user 消息，调用 **DeepSeek-R1-Distill**（通过 vLLM 提供的 OpenAI 兼容接口）。
- 取得**模型回复文字**，用于步骤 4 的 TTS。

#### 3.2 大模型服务

- 部署方式见 `doc/vllm-deepseek-r1-windows.md`：在 WSL2/Ubuntu 或本机用 vLLM 启动，例如：  
  `--model deepseek-ai/DeepSeek-R1-Distill-Qwen-7B`，`--host 0.0.0.0`，`--port 8000`。
- 若 Spring Boot 与 vLLM 不在同一台机，需保证网络可达（同机用 `localhost:8000`，跨机用内网 IP 或内网穿透）。

#### 3.3 请求格式（OpenAI 兼容）

- **URL**：`http://vLLM服务地址:8000/v1/chat/completions`
- **方法**：POST，`Content-Type: application/json`
- **Body 示例**：
```json
{
  "model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
  "messages": [
    { "role": "user", "content": "这里填步骤2得到的用户文字" }
  ],
  "max_tokens": 512
}
```
- **响应**：从 `choices[0].message.content` 取出**助手回复文字**，供步骤 4 使用。

#### 3.4 Spring Boot 实现

- 使用 `RestTemplate` 或 `WebClient` 发送上述 JSON，解析返回的 `content` 即可。
- 可增加超时、重试；若希望多轮对话，可在 `messages` 中保留历史（user/assistant 交替）。

#### 3.5 与文档对应

- vLLM 启动与测试：`doc/vllm-deepseek-r1-windows.md` 第四、五节。

---

### 步骤 4：将大模型返回的文字转为语音（TTS）

#### 4.1 目标

- 用**步骤 3 得到的回复文字**调用 PaddleSpeech TTS，生成**语音文件**（WAV 或 MP3）。
- 该文件将提供给 ESP32 下载并播放（步骤 5、6）。

#### 4.2 调用方式

**方式 A：命令行**

- 见 `doc/PaddleSpeech-本地部署.md` 第四节：  
  `paddlespeech tts --input "回复文字" --output reply.wav`
- Spring Boot 将回复文字写临时文件或通过 stdin 传给脚本，执行上述命令（或等价的 Python 调用），得到 `reply.wav`（或转为 MP3 以减小体积）。

**方式 B：PaddleSpeech TTS 服务**

- 启动 PaddleSpeech 的 TTS 服务（或流式 TTS 服务），Spring Boot 用 HTTP 请求该服务，传入文本，取回音频流或文件路径。

#### 4.3 格式与存储

- 默认输出多为 24kHz WAV；若 ESP32 端用 MP3 解码（如 libhelix），可在后端用 ffmpeg 转为 MP3 再提供下载，减小传输量。
- 将生成的文件保存到静态目录或对象存储，并得到**可访问的 URL**（如 `http://后端IP:端口/tts/xxx.mp3`），供步骤 5 返回给 ESP32。

#### 4.4 与文档对应

- TTS 安装与调用：`doc/PaddleSpeech-本地部署.md` 第四节。
- 若 TTS 以服务形式部署，跨网访问同样参考该文档「不在同一局域网时如何调用」。

---

### 步骤 5：将音频下发给 ESP32

#### 5.1 目标

- ESP32 需要拿到「要播放的音频」的**下载地址**或**数据流**，然后拉取并播放（步骤 6）。

#### 5.2 两种常见方式

**方式 A：响应里带 URL（推荐，与现有文档一致）**

- 步骤 1～4 在后端串联完成后，Spring Boot 的**同一请求的响应**（或专门的「轮询/查询」接口）中返回：  
  `{ "text": "大模型回复文字", "audioUrl": "http://服务器:端口/tts/reply_xxx.mp3" }`  
- ESP32 在收到 200 且带 `audioUrl` 后，用该 URL 做 **HTTP GET**，将得到 MP3 数据，再交给步骤 6 解码播放。
- 若 ESP32 与后端不在同一局域网，需在服务器或内网穿透中暴露该 URL（见 `doc/PaddleSpeech-本地部署.md` 跨网调用一节）。

**方式 B：WebSocket 推送**

- 上传后不阻塞等待整条链路完成，而是先返回「任务已接受」，后端异步执行 ASR → 大模型 → TTS，完成后通过 WebSocket 把 `audioUrl` 或音频二进制推给该 ESP32。ESP32 再按 URL 下载或直接播放推送的片段。
- 实现复杂度较高，建议先实现方式 A。

#### 5.3 与文档对应

- 「服务器提供 TTS 的 MP3 URL，ESP32 通过 HTTP GET 下载」：`doc/ESP32-I2S网络音频播放.md` 整体架构与数据流。

---

### 步骤 6：ESP32 用 MAX98357A 播放声音

#### 6.1 目标

- ESP32 从步骤 5 拿到的 **audioUrl** 发起 **HTTP GET**，接收 MP3（或 WAV）数据。
- 若为 MP3：用 **libhelix**（或 minimp3）解码为 PCM；若为 WAV：可解析头后直接取 PCM。
- 将 PCM 通过 **I2S** 输出到 **MAX98357A**，驱动喇叭播放。

#### 6.2 硬件

- 按 `doc/ESP32-I2S网络音频播放.md` 第三、四节：  
  ESP32 的 GPIO25/26/22 接 MAX98357A 的 DIN/BCLK/LRC，喇叭接 OUT+/OUT-，供电共地。

#### 6.3 软件要点

- **I2S 配置**：采样率、位深与 TTS 输出一致（如 24kHz 或 16kHz、16bit）；若 TTS 为单声道，I2S 可配单声道或左右同数据。
- **缓冲**：边下载边解码边写 I2S，或先下载到内存/PSRAM 再整段解码播放，避免卡顿。
- **格式**：优先使用 MP3（体积小），ESP32 侧需集成 MP3 解码库；若只支持 WAV，则后端只提供 WAV 并保证格式与 I2S 配置一致。

#### 6.4 与文档对应

- 接线与 I2S 播放流程：`doc/ESP32-I2S网络音频播放.md` 全文。
- 灯光控制项目中的 WiFi/HTTP 使用方式可参考：`doc/硬件灯光控制-AI指令流程.md`（仅作 HTTP 与 WiFi 参考，播放逻辑以 I2S 文档为准）。

---

## 四、端到端接口约定（建议）

便于前后端与 ESP32 联调，可约定如下（可按需调整）：

| 接口 | 方法 | 说明 | 响应示例 |
|------|------|------|----------|
| `/api/voice/upload` | POST | ESP32 上传 WAV，multipart 字段 `file` | `{ "text": "识别文字", "reply": "大模型回复", "audioUrl": "http://.../tts/xxx.mp3" }` |
| `GET /tts/xxx.mp3` | GET | ESP32 根据 `audioUrl` 下载音频 | 二进制 MP3 流 |

- 若希望「上传」与「取结果」分离，可改为：  
  - `POST /api/voice/upload` 返回 `{ "taskId": "xxx" }`  
  - `GET /api/voice/result?taskId=xxx` 返回 `{ "text", "reply", "audioUrl" }`，ESP32 轮询直到有结果再下载 `audioUrl`。

---

## 五、依赖文档与顺序

| 顺序 | 文档 | 用途 |
|------|------|------|
| 1 | `doc/PaddleSpeech-本地部署.md` | 部署 ASR/TTS，命令行与（可选）服务模式 |
| 2 | `doc/vllm-deepseek-r1-windows.md` | 部署 DeepSeek-R1-Distill，获取 chat completions 接口 |
| 3 | `doc/ESP32-I2S网络音频播放.md` | ESP32 接 MAX98357A、下载 MP3、I2S 播放 |
| 4 | `doc/硬件灯光控制-AI指令流程.md` | 参考 WiFi、HTTP 在 ESP32 上的使用方式 |
| 5 | 本文档 | 串联 1～6 步，形成端到端计划与实现说明 |

---

## 六、实现顺序建议

1. **后端串联（无 ESP32）**：用 Postman 上传一段 16kHz WAV，Spring Boot 完成 ASR → 调 vLLM → TTS → 返回 `audioUrl`，浏览器可播放该 URL。
2. **ESP32 仅播放**：后端固定返回一个测试用 `audioUrl`，ESP32 只做 HTTP GET + I2S 播放（参考 `doc/ESP32-I2S网络音频播放.md`）。
3. **ESP32 录音与上传**：接好 I2S 麦克风，实现 16kHz WAV 录音与 POST 上传，后端仍用该上传做 ASR，后续链路同 1。
4. **全链路**：ESP32 上传 → 后端 ASR → 大模型 → TTS → 返回 `audioUrl` → ESP32 下载并播放，并按需做超时、错误提示与重试。

完成以上步骤后，即实现：**声音传感器（麦克风）采集 → Spring Boot + PaddleSpeech ASR 转文字 → DeepSeek-R1-Distill 生成回复 → PaddleSpeech TTS 转语音 → 音频下发给 ESP32 → MAX98357A 喇叭播放** 的完整闭环。
